[{"id": "identity_6763", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGet an artists top tracks per country with their ID.\n\n        Parameters\n        ----------\n        spotify_id : str\n            The spotify_id to search by.\n        country : COUNTRY_TP\n            COUNTRY"}]}, {"id": "identity_2421", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nInstance depends on the API version:\n\n           * 2016-04-01: :class:`ZonesOperations<azure.mgmt.dns.v2016_04_01.operations.ZonesOperations>`\n           * 2018-03-01-preview: :class:`ZonesOperations<azure.mgmt.dns.v2018_03_01_preview.operations.ZonesOperations>`\n           * 2018-05-01: :class:`ZonesOperations<azure.mgmt.dns.v2018_05_01.operations.ZonesOperations>`"}]}, {"id": "identity_9798", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nrun_git_log([git_dir]) -> File\n\n    Run `git log --numstat --pretty=raw` on the specified\n    git repository and return its stdout as a pseudo-File."}]}, {"id": "identity_3815", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nTransform a QuantumChannel to the Operator representation."}]}, {"id": "identity_15", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nExtracts video ID from live.qq.com."}]}, {"id": "identity_1588", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturns (batched) matmul of a SparseTensor (or Tensor) with a Tensor.\n\n  Args:\n    sparse_or_dense_a: `SparseTensor` or `Tensor` representing a (batch of)\n      matrices.\n    dense_b: `Tensor` representing a (batch of) matrices, with the same batch\n      shape as `sparse_or_dense_a`. The shape must be compatible with the shape\n      of `sparse_or_dense_a` and kwargs.\n    validate_args: When `True`, additional assertions might be embedded in the\n      graph.\n      Default value: `False` (i.e., no graph assertions are added).\n    name: Python `str` prefixed to ops created by this function.\n      Default value: \"sparse_or_dense_matmul\".\n    **kwargs: Keyword arguments to `tf.sparse_tensor_dense_matmul` or\n      `tf.matmul`.\n\n  Returns:\n    product: A dense (batch of) matrix-shaped Tensor of the same batch shape and\n    dtype as `sparse_or_dense_a` and `dense_b`. If `sparse_or_dense_a` or\n    `dense_b` is adjointed through `kwargs` then the shape is adjusted\n    accordingly."}]}, {"id": "identity_6811", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nAttributes used when constructing url parameters."}]}, {"id": "identity_6555", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nThis function is the final common pathway of program:\n\n    Print initial balance if requested;\n    Print transactions surviving de-duplication filter;\n    Print balance assertions if requested;\n    Print commodity prices obtained from position statements"}]}, {"id": "identity_5682", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCheck equality of nodes based on the comparison of their attributes named attr_name.\n\n    Args:\n        node_a (astroid.node): first node to compare.\n        node_b (astroid.node): second node to compare.\n        attr_name (str): name of the nodes attribute to use for comparison.\n\n    Returns:\n        bool: True if node_a.attr_name == node_b.attr_name, False otherwise."}]}, {"id": "identity_8667", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCreate a new contact.\n\n    :param selected_address_books: a list of addressbooks that were selected on\n        the command line\n    :type selected_address_books: list of address_book.AddressBook\n    :param input_from_stdin_or_file: the data for the new contact as a yaml\n        formatted string\n    :type input_from_stdin_or_file: str\n    :param open_editor: whether to open the new contact in the edior after\n        creation\n    :type open_editor: bool\n    :returns: None\n    :rtype: None"}]}, {"id": "identity_146", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nDelete an existing document out of a collection in the CosmosDB database."}]}, {"id": "identity_1696", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nmodel predict images, return imageFrame with predicted tensor\n        :param image_frame imageFrame that contains images\n        :param output_layer if output_layer is not null, the output of layer that matches\n        output_layer will be used as predicted output\n        :param share_buffer whether to share same memory for each batch predict results\n        :param batch_per_partition batch size per partition, default is 4\n        :param predict_key key to store predicted results"}]}, {"id": "identity_9797", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nAccept a parsed single commit. Some of the named groups\n    require further processing, so parse those groups.\n    Return a dictionary representing the completely parsed\n    commit."}]}, {"id": "identity_9062", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGiven a file-like object containing a JSON stream, upload it to\n    Luminoso with the given account name and project name."}]}, {"id": "identity_3604", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGetConversationPagedMembers.\n\n        Enumerate the members of a conversation one page at a time.\n        This REST API takes a ConversationId. Optionally a pageSize and/or\n        continuationToken can be provided. It returns a PagedMembersResult,\n        which contains an array\n        of ChannelAccounts representing the members of the conversation and a\n        continuation token that can be used to get more values.\n        One page of ChannelAccounts records are returned with each call. The\n        number of records in a page may vary between channels and calls. The\n        pageSize parameter can be used as\n        a suggestion. If there are no additional results the response will not\n        contain a continuation token. If there are no members in the\n        conversation the Members will be empty or not present in the response.\n        A response to a request that has a continuation token from a prior\n        request may rarely return members from a previous request.\n\n        :param conversation_id: Conversation ID\n        :type conversation_id: str\n        :param page_size: Suggested page size\n        :type page_size: int\n        :param continuation_token: Continuation Token\n        :type continuation_token: str\n        :param dict custom_headers: headers that will be added to the request\n        :param bool raw: returns the direct response alongside the\n         deserialized response\n        :param operation_config: :ref:`Operation configuration\n         overrides<msrest:optionsforoperations>`.\n        :return: PagedMembersResult or ClientRawResponse if raw=true\n        :rtype: ~botframework.connector.models.PagedMembersResult or\n         ~msrest.pipeline.ClientRawResponse\n        :raises:\n         :class:`HttpOperationError<msrest.exceptions.HttpOperationError>`"}]}, {"id": "identity_1403", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nA simplified version of `tf.scan` that has configurable tracing.\n\n  This function repeatedly calls `loop_fn(state, elem)`, where `state` is the\n  `initial_state` during the first iteration, and the return value of `loop_fn`\n  for every iteration thereafter. `elem` is a slice of `elements` along the\n  first dimension, accessed in order. Additionally, it calls `trace_fn` on the\n  return value of `loop_fn`. The `Tensor`s in return values of `trace_fn` are\n  stacked and returned from this function, such that the first dimension of\n  those `Tensor`s matches the size of `elems`.\n\n  Args:\n    loop_fn: A callable that takes in a `Tensor` or a nested collection of\n      `Tensor`s with the same structure as `initial_state`, a slice of `elems`\n      and returns the same structure as `initial_state`.\n    initial_state: A `Tensor` or a nested collection of `Tensor`s passed to\n      `loop_fn` in the first iteration.\n    elems: A `Tensor` that is split along the first dimension and each element\n      of which is passed to `loop_fn`.\n    trace_fn: A callable that takes in the return value of `loop_fn` and returns\n      a `Tensor` or a nested collection of `Tensor`s.\n    parallel_iterations: Passed to the internal `tf.while_loop`.\n    name: Name scope used in this function. Default: 'trace_scan'.\n\n  Returns:\n    final_state: The final return value of `loop_fn`.\n    trace: The same structure as the return value of `trace_fn`, but with each\n      `Tensor` being a stack of the corresponding `Tensors` in the return value\n      of `trace_fn` for each slice of `elems`."}]}, {"id": "identity_2457", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGets status text of response."}]}, {"id": "identity_5795", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCheck that there are not unnecessary parens after a keyword.\n\n        Parens are unnecessary if there is exactly one balanced outer pair on a\n        line, and it is followed by a colon, and contains no commas (i.e. is not a\n        tuple).\n\n        Args:\n        tokens: list of Tokens; the entire list of Tokens.\n        start: int; the position of the keyword in the token list."}]}, {"id": "identity_9398", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nTakes a spectrogram and returns a 2D array of the form:\n\n    0 0 0 1 0 0 1 0 0 0 1   <-- Frequency 0\n    0 0 1 0 0 0 0 0 0 1 0   <-- Frequency 1\n    0 0 0 0 0 0 1 0 1 0 0   <-- Frequency 2\n    *** Time axis *******\n\n    Where a 1 means that the value in that time bin in the spectrogram corresponds to\n    a peak/valley in the first derivative.\n\n    This function is used as part of the ASA algorithm and is not meant to be used publicly."}]}, {"id": "identity_6868", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nSwitch PyFunceble.CONFIGURATION variables to their opposite.\n\n        :param variable:\n            The variable name to switch.\n            The variable should be an index our configuration system.\n            If we want to switch a bool variable, we should parse\n            it here.\n        :type variable: str|bool\n\n        :param custom:\n            Let us know if have to switch the parsed variable instead\n            of our configuration index.\n        :type custom: bool\n\n        :return:\n            The opposite of the configuration index or the given variable.\n        :rtype: bool\n\n        :raises:\n            :code:`Exception`\n                When the configuration is not valid. In other words,\n                if the PyFunceble.CONFIGURATION[variable_name] is not a bool."}]}, {"id": "identity_9578", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\ngenerate _sig for each interface which has no subinterface\n        if already has _sig return it instead\n\n        :param context: instance of RtlNetlist where signals should be created\n        :param prefix: name prefix for created signals\n        :param typeTransform: optional function (type) returns modified type\n            for signal"}]}, {"id": "identity_7495", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\n**Description**\n            Adds a panel to the dashboard. A panel can be a time series, or a top chart (i.e. bar chart), or a number panel.\n\n        **Arguments**\n            - **dashboard**: dashboard to edit\n            - **name**: name of the new panel\n            - **panel_type**: type of the new panel. Valid values are: ``timeSeries``, ``top``, ``number``\n            - **metrics**:  a list of dictionaries, specifying the metrics to show in the panel, and optionally, if there is only one metric, a grouping key to segment that metric by. A metric is any of the entries that can be found in the *Metrics* section of the Explore page in Sysdig Monitor. Metric entries require an *aggregations* section specifying how to aggregate the metric across time and groups of containers/hosts. A grouping key is any of the entries that can be found in the *Show* or *Segment By* sections of the Explore page in Sysdig Monitor. Refer to the examples section below for ready to use code snippets. Note, certain panels allow certain combinations of metrics and grouping keys:\n                - ``timeSeries``: 1 or more metrics OR 1 metric + 1 grouping key\n                - ``top``: 1 or more metrics OR 1 metric + 1 grouping key\n                - ``number``: 1 metric only\n            - **scope**: filter to apply to the panel; must be based on metadata available in Sysdig Monitor; Example: *kubernetes.namespace.name='production' and container.image='nginx'*.\n            - **sort_by**: Data sorting; The parameter is optional and it's a dictionary of ``metric`` and ``mode`` (it can be ``desc`` or ``asc``)\n            - **limit**: This parameter sets the limit on the number of lines/bars shown in a ``timeSeries`` or ``top`` panel. In the case of more entities being available than the limit, the top entities according to the sort will be shown. The default value is 10 for ``top`` panels (for ``timeSeries`` the default is defined by Sysdig Monitor itself). Note that increasing the limit above 10 is not officially supported and may cause performance and rendering issues\n            - **layout**: Size and position of the panel. The dashboard layout is defined by a grid of 12 columns, each row height is equal to the column height. For example, say you want to show 2 panels at the top: one panel might be 6 x 3 (half the width, 3 rows height) located in row 1 and column 1 (top-left corner of the viewport), the second panel might be 6 x 3 located in row 1 and position 7. The location is specified by a dictionary of ``row`` (row position), ``col`` (column position), ``size_x`` (width), ``size_y`` (height).\n\n        **Success Return Value**\n            A dictionary showing the details of the edited dashboard.\n\n        **Example**\n            `examples/dashboard.py <https://github.com/draios/python-sdc-client/blob/master/examples/dashboard.py>`_"}]}, {"id": "identity_5999", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCreate a CRL object with 100 Revoked objects, then call the\n        get_revoked method repeatedly."}]}, {"id": "identity_8859", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nIf f_back is looking at a call function, return\n    the name for it. Otherwise return None"}]}, {"id": "identity_9957", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nConfigures this extension with the given app. This registers an\n        ``teardown_appcontext`` call, and attaches this ``LDAP3LoginManager``\n        to it as ``app.ldap3_login_manager``.\n\n        Args:\n            app (flask.Flask): The flask app to initialise with"}]}, {"id": "identity_4645", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\n:returns: datasketch.MinHash -- A copy of this MinHash by exporting its state."}]}, {"id": "identity_809", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCheck for the existence of a path in HDFS by querying FileStatus.\n\n        :param hdfs_path: The path to check.\n        :type hdfs_path: str\n        :return: True if the path exists and False if not.\n        :rtype: bool"}]}, {"id": "identity_2016", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturn True if the variable matches this type, and False otherwise."}]}, {"id": "identity_1460", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nImplements Markov chain Monte Carlo via repeated `TransitionKernel` steps.\n\n  This function samples from an Markov chain at `current_state` and whose\n  stationary distribution is governed by the supplied `TransitionKernel`\n  instance (`kernel`).\n\n  This function can sample from multiple chains, in parallel. (Whether or not\n  there are multiple chains is dictated by the `kernel`.)\n\n  The `current_state` can be represented as a single `Tensor` or a `list` of\n  `Tensors` which collectively represent the current state.\n\n  Since MCMC states are correlated, it is sometimes desirable to produce\n  additional intermediate states, and then discard them, ending up with a set of\n  states with decreased autocorrelation.  See [Owen (2017)][1]. Such \"thinning\"\n  is made possible by setting `num_steps_between_results > 0`. The chain then\n  takes `num_steps_between_results` extra steps between the steps that make it\n  into the results. The extra steps are never materialized (in calls to\n  `sess.run`), and thus do not increase memory requirements.\n\n  Warning: when setting a `seed` in the `kernel`, ensure that `sample_chain`'s\n  `parallel_iterations=1`, otherwise results will not be reproducible.\n\n  In addition to returning the chain state, this function supports tracing of\n  auxiliary variables used by the kernel. The traced values are selected by\n  specifying `trace_fn`. By default, all kernel results are traced but in the\n  future the default will be changed to no results being traced, so plan\n  accordingly. See below for some examples of this feature.\n\n  Args:\n    num_results: Integer number of Markov chain draws.\n    current_state: `Tensor` or Python `list` of `Tensor`s representing the\n      current state(s) of the Markov chain(s).\n    previous_kernel_results: A `Tensor` or a nested collection of `Tensor`s\n      representing internal calculations made within the previous call to this\n      function (or as returned by `bootstrap_results`).\n    kernel: An instance of `tfp.mcmc.TransitionKernel` which implements one step\n      of the Markov chain.\n    num_burnin_steps: Integer number of chain steps to take before starting to\n      collect results.\n      Default value: 0 (i.e., no burn-in).\n    num_steps_between_results: Integer number of chain steps between collecting\n      a result. Only one out of every `num_steps_between_samples + 1` steps is\n      included in the returned results.  The number of returned chain states is\n      still equal to `num_results`.  Default value: 0 (i.e., no thinning).\n    trace_fn: A callable that takes in the current chain state and the previous\n      kernel results and return a `Tensor` or a nested collection of `Tensor`s\n      that is then traced along with the chain state.\n    return_final_kernel_results: If `True`, then the final kernel results are\n      returned alongside the chain state and the trace specified by the\n      `trace_fn`.\n    parallel_iterations: The number of iterations allowed to run in parallel. It\n      must be a positive integer. See `tf.while_loop` for more details.\n    name: Python `str` name prefixed to Ops created by this function.\n      Default value: `None` (i.e., \"mcmc_sample_chain\").\n\n  Returns:\n    checkpointable_states_and_trace: if `return_final_kernel_results` is\n      `True`. The return value is an instance of\n      `CheckpointableStatesAndTrace`.\n    all_states: if `return_final_kernel_results` is `False` and `trace_fn` is\n      `None`. The return value is a `Tensor` or Python list of `Tensor`s\n      representing the state(s) of the Markov chain(s) at each result step. Has\n      same shape as input `current_state` but with a prepended\n      `num_results`-size dimension.\n    states_and_trace: if `return_final_kernel_results` is `False` and\n      `trace_fn` is not `None`. The return value is an instance of\n      `StatesAndTrace`.\n\n  #### Examples\n\n  ##### Sample from a diagonal-variance Gaussian.\n\n  I.e.,\n\n  ```none\n  for i=1..n:\n    x[i] ~ MultivariateNormal(loc=0, scale=diag(true_stddev))  # likelihood\n  ```\n\n  ```python\n  import tensorflow as tf\n  import tensorflow_probability as tfp\n  tfd = tfp.distributions\n\n  dims = 10\n  true_stddev = np.sqrt(np.linspace(1., 3., dims))\n  likelihood = tfd.MultivariateNormalDiag(loc=0., scale_diag=true_stddev)\n\n  states = tfp.mcmc.sample_chain(\n      num_results=1000,\n      num_burnin_steps=500,\n      current_state=tf.zeros(dims),\n      kernel=tfp.mcmc.HamiltonianMonteCarlo(\n        target_log_prob_fn=likelihood.log_prob,\n        step_size=0.5,\n        num_leapfrog_steps=2),\n      trace_fn=None)\n\n  sample_mean = tf.reduce_mean(states, axis=0)\n  # ==> approx all zeros\n\n  sample_stddev = tf.sqrt(tf.reduce_mean(\n      tf.squared_difference(states, sample_mean),\n      axis=0))\n  # ==> approx equal true_stddev\n  ```\n\n  ##### Sampling from factor-analysis posteriors with known factors.\n\n  I.e.,\n\n  ```none\n  # prior\n  w ~ MultivariateNormal(loc=0, scale=eye(d))\n  for i=1..n:\n    # likelihood\n    x[i] ~ Normal(loc=w^T F[i], scale=1)\n  ```\n\n  where `F` denotes factors.\n\n  ```python\n  import tensorflow as tf\n  import tensorflow_probability as tfp\n  tfd = tfp.distributions\n\n  # Specify model.\n  def make_prior(dims):\n    return tfd.MultivariateNormalDiag(\n        loc=tf.zeros(dims))\n\n  def make_likelihood(weights, factors):\n    return tfd.MultivariateNormalDiag(\n        loc=tf.matmul(weights, factors, adjoint_b=True))\n\n  def joint_log_prob(num_weights, factors, x, w):\n    return (make_prior(num_weights).log_prob(w) +\n            make_likelihood(w, factors).log_prob(x))\n\n  def unnormalized_log_posterior(w):\n    # Posterior is proportional to: `p(W, X=x | factors)`.\n    return joint_log_prob(num_weights, factors, x, w)\n\n  # Setup data.\n  num_weights = 10 # == d\n  num_factors = 40 # == n\n  num_chains = 100\n\n  weights = make_prior(num_weights).sample(1)\n  factors = tf.random_normal([num_factors, num_weights])\n  x = make_likelihood(weights, factors).sample()\n\n  # Sample from Hamiltonian Monte Carlo Markov Chain.\n\n  # Get `num_results` samples from `num_chains` independent chains.\n  chains_states, kernels_results = tfp.mcmc.sample_chain(\n      num_results=1000,\n      num_burnin_steps=500,\n      current_state=tf.zeros([num_chains, num_weights], name='init_weights'),\n      kernel=tfp.mcmc.HamiltonianMonteCarlo(\n        target_log_prob_fn=unnormalized_log_posterior,\n        step_size=0.1,\n        num_leapfrog_steps=2))\n\n  # Compute sample stats.\n  sample_mean = tf.reduce_mean(chains_states, axis=[0, 1])\n  # ==> approx equal to weights\n\n  sample_var = tf.reduce_mean(\n      tf.squared_difference(chains_states, sample_mean),\n      axis=[0, 1])\n  # ==> less than 1\n  ```\n\n  ##### Custom tracing functions.\n\n  ```python\n  import tensorflow as tf\n  import tensorflow_probability as tfp\n  tfd = tfp.distributions\n\n  likelihood = tfd.Normal(loc=0., scale=1.)\n\n  def sample_chain(trace_fn):\n    return tfp.mcmc.sample_chain(\n      num_results=1000,\n      num_burnin_steps=500,\n      current_state=0.,\n      kernel=tfp.mcmc.HamiltonianMonteCarlo(\n        target_log_prob_fn=likelihood.log_prob,\n        step_size=0.5,\n        num_leapfrog_steps=2),\n      trace_fn=trace_fn)\n\n  def trace_log_accept_ratio(states, previous_kernel_results):\n    return previous_kernel_results.log_accept_ratio\n\n  def trace_everything(states, previous_kernel_results):\n    return previous_kernel_results\n\n  _, log_accept_ratio = sample_chain(trace_fn=trace_log_accept_ratio)\n  _, kernel_results = sample_chain(trace_fn=trace_everything)\n\n  acceptance_prob = tf.exp(tf.minimum(log_accept_ratio_, 0.))\n  # Equivalent to, but more efficient than:\n  acceptance_prob = tf.exp(tf.minimum(kernel_results.log_accept_ratio_, 0.))\n  ```\n\n  #### References\n\n  [1]: Art B. Owen. Statistically efficient thinning of a Markov chain sampler.\n       _Technical Report_, 2017.\n       http://statweb.stanford.edu/~owen/reports/bestthinning.pdf"}]}, {"id": "identity_2840", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nList session IDs.\n\n        List the Session IDs with pending messages in the queue where the state of the session\n        has been updated since the timestamp provided. If no timestamp is provided, all will be returned.\n        If the state of a session has never been set, it will not be returned regardless of whether\n        there are messages pending.\n\n        :param updated_since: The UTC datetime from which to return updated pending Session IDs.\n        :type updated_since: datetime.datetime\n        :param max_results: The maximum number of Session IDs to return. Default value is 100.\n        :type max_results: int\n        :param skip: The page value to jump to. Default value is 0.\n        :type skip: int\n        :rtype: list[str]\n\n        Example:\n            .. literalinclude:: ../examples/test_examples.py\n                :start-after: [START list_sessions_service_bus]\n                :end-before: [END list_sessions_service_bus]\n                :language: python\n                :dedent: 4\n                :caption: Get the Ids of session which have messages pending in the queue"}]}, {"id": "identity_5905", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCreates Grant object with the given params\n\n        :param client_id: ID of the client\n        :param code:\n        :param request: OAuthlib request object"}]}, {"id": "identity_5123", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nRetrieve all the fields available."}]}, {"id": "identity_5966", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nValidate access token.\n\n        :param token: A string of random characters\n        :param scopes: A list of scopes\n        :param request: The Request object passed by oauthlib\n\n        The validation validates:\n\n            1) if the token is available\n            2) if the token has expired\n            3) if the scopes are available"}]}, {"id": "identity_5703", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\ncheck that accessed members are defined"}]}, {"id": "identity_7915", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturn normal form of self.name.\n\n        - Remove comments.\n        - Remove language code.\n        - Remove namespace (\"template:\" or any of `localized_namespaces`.\n        - Use space instead of underscore.\n        - Remove consecutive spaces.\n        - Use uppercase for the first letter if `capitalize`.\n        - Remove #anchor.\n\n        :param rm_namespaces: is used to provide additional localized\n            namespaces for the template namespace. They will be removed from\n            the result. Default is ('Template',).\n        :param capitalize: If True, convert the first letter of the\n            template's name to a capital letter. See\n            [[mw:Manual:$wgCapitalLinks]] for more info.\n        :param code: is the language code.\n        :param capital_links: deprecated.\n        :param _code: deprecated.\n\n        Example:\n            >>> Template(\n            ...     '{{ eN : tEmPlAtE : <!-- c --> t_1 # b | a }}'\n            ... ).normal_name(code='en')\n            'T 1'"}]}, {"id": "identity_5004", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nActivate output arguments parsing"}]}, {"id": "identity_8544", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nPrints out a Yum-style progress bar (via sys.stdout.write).\n    `start`: The 'current' value of the progress bar.\n    `end`: The '100%' value of the progress bar.\n    `bar_length`: The size of the overall progress bar.\n\n    Example output with start=20, end=100, bar_length=50:\n    [###########----------------------------------------] 20/100 (100%)\n\n    Intended to be used in a loop. Example:\n    end = 100\n    for i in range(end):\n        cli_progress_bar(i, end)\n\n    Based on an implementation found here:\n        http://stackoverflow.com/a/13685020/1149774"}]}, {"id": "identity_9329", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturns JavaScript that:\n\n        #.  Triggers the ``options.onLoginComplete(result, closer)``\n            handler set with the :ref:`authomatic.setup() <js_setup>`\n            function of :ref:`javascript.js <js>`.\n        #.  Calls the JavasScript callback specified by :data:`callback_name`\n            on the opener of the *login handler popup* and passes it the\n            *login result* JSON object as first argument and the `closer`\n            function which you should call in your callback to close the popup.\n\n        :param str callback_name:\n            The name of the javascript callback e.g ``foo.bar.loginCallback``\n            will result in ``window.opener.foo.bar.loginCallback(result);``\n            in the HTML.\n\n        :param int indent:\n            The number of spaces to indent the JSON result object.\n            If ``0`` or negative, only newlines are added.\n            If ``None``, no newlines are added.\n\n        :param custom:\n            Any JSON serializable object that will be passed to the\n            ``result.custom`` attribute.\n\n        :param str stay_open:\n            If ``True``, the popup will stay open.\n\n        :returns:\n            :class:`str` with JavaScript."}]}, {"id": "identity_6332", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCreate a new mesh that is a resampled version of the current one.\n\n    The resampling is done by building a uniform volumetric representation\n    where each voxel contains the signed distance from the original surface.\n    The resampled surface is reconstructed using the marching cube algorithm\n    over this volume.\n\n    Args:\n        script: the FilterScript object or script filename to write\n            the filter to.\n        voxel (float): voxel (cell) size for resampling. Smaller cells give\n            better precision at a higher computational cost. Remember that\n            halving the cell size means that you build a volume 8 times larger.\n        offset (float): offset amount of the created surface (i.e. distance of\n            the created surface from the original one). If offset is zero, the\n            created surface passes on the original mesh itself. Values greater\n            than zero mean an external surface (offset), and lower than zero\n            mean an internal surface (inset). In practice this value is the\n            threshold passed to the Marching Cube algorithm to extract the\n            isosurface from the distance field representation.\n        merge_vert (bool): if True the mesh generated by MC will be cleaned by\n            unifying vertices that are almost coincident.\n        discretize (bool): if True the position of the intersected edge of the\n            marching cube grid is not computed by linear interpolation, but it\n            is placed in fixed middle position. As a consequence the resampled\n            object will look severely aliased by a stairstep appearance. Useful\n            only for simulating the output of 3D printing devices.\n        multisample (bool): if True the distance field is more accurately\n            compute by multisampling the volume (7 sample for each voxel). Much\n            slower but less artifacts.\n        thicken (bool): if True, you have to choose a non zero Offset and a\n            double surface is built around the original surface, inside and\n            outside. Is useful to convert thin floating surfaces into solid,\n            thick meshes.\n\n    Layer stack:\n        Creates 1 new layer 'Offset mesh'\n        Current layer is changed to new layer\n\n    MeshLab versions:\n        2016.12\n        1.3.4BETA"}]}, {"id": "identity_4122", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nDistance abs"}]}, {"id": "identity_3917", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nMap all gates that can be executed with the current layout.\n\n    Args:\n        layout (Layout): Map from virtual qubit index to physical qubit index.\n        gates (list): Gates to be mapped.\n        coupling_map (CouplingMap): CouplingMap for target device topology.\n\n    Returns:\n        tuple:\n            mapped_gates (list): ops for gates that can be executed, mapped onto layout.\n            remaining_gates (list): gates that cannot be executed on the layout."}]}, {"id": "identity_7468", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\n**Description**\n            Removes a panel from the dashboard. The panel to remove is identified by the specified ``name``.\n\n        **Arguments**\n            - **name**: name of the panel to find and remove\n\n        **Success Return Value**\n            A dictionary showing the details of the edited dashboard.\n\n        **Example**\n            `examples/dashboard.py <https://github.com/draios/python-sdc-client/blob/master/examples/dashboard.py>`_"}]}, {"id": "identity_1124", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nSplit a covariance matrix into block-diagonal marginals of given sizes."}]}, {"id": "identity_9828", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturn a memory-map of the elements `start` through `end`.\n\n        The memory map will offer the 8-byte double-precision floats\n        (\"elements\") in the file from index `start` through to the index\n        `end`, inclusive, both counting the first float as element 1.\n        Memory maps must begin on a page boundary, so `skip` returns the\n        number of extra bytes at the beginning of the return value."}]}, {"id": "identity_4045", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nSelect the best remaining hardware qubit for the next program qubit."}]}, {"id": "identity_1689", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGet the model parameters which containing: weight, bias, gradBias, gradWeight\n\n        :return: dict(layername -> dict(parametername -> ndarray))"}]}, {"id": "identity_2432", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nInstance depends on the API version:\n\n           * 2015-08-01: :class:`ConsumerGroupsOperations<azure.mgmt.eventhub.v2015_08_01.operations.ConsumerGroupsOperations>`\n           * 2017-04-01: :class:`ConsumerGroupsOperations<azure.mgmt.eventhub.v2017_04_01.operations.ConsumerGroupsOperations>`"}]}, {"id": "identity_5076", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGet the user public organizations"}]}, {"id": "identity_1125", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nUtility method to decompose a joint posterior into components.\n\n  Args:\n    model: `tfp.sts.Sum` instance defining an additive STS model.\n    posterior_means: float `Tensor` of shape `concat(\n      [[num_posterior_draws], batch_shape, num_timesteps, latent_size])`\n      representing the posterior mean over latents in an\n      `AdditiveStateSpaceModel`.\n    posterior_covs: float `Tensor` of shape `concat(\n      [[num_posterior_draws], batch_shape, num_timesteps,\n      latent_size, latent_size])`\n      representing the posterior marginal covariances over latents in an\n      `AdditiveStateSpaceModel`.\n    parameter_samples: Python `list` of `Tensors` representing posterior\n      samples of model parameters, with shapes `[concat([\n      [num_posterior_draws], param.prior.batch_shape,\n      param.prior.event_shape]) for param in model.parameters]`. This may\n      optionally also be a map (Python `dict`) of parameter names to\n      `Tensor` values.\n\n  Returns:\n    component_dists: A `collections.OrderedDict` instance mapping\n      component StructuralTimeSeries instances (elements of `model.components`)\n      to `tfd.Distribution` instances representing the posterior marginal\n      distributions on the process modeled by each component. Each distribution\n      has batch shape matching that of `posterior_means`/`posterior_covs`, and\n      event shape of `[num_timesteps]`."}]}, {"id": "identity_4441", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nWrite stepper info to json"}]}, {"id": "identity_7902", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturn a list of templates as template objects."}]}, {"id": "identity_5232", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nThis method lets users rate a movie. A valid session id or guest\n        session id is required.\n\n        Args:\n            session_id: see Authentication.\n            guest_session_id: see Authentication.\n            value: Rating value.\n\n        Returns:\n            A dict representation of the JSON returned from the API."}]}, {"id": "identity_2917", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nBrute force regex based HTML tag parser. This is a rough-and-ready searcher to find HTML tags when\n    standards compliance is not required. Will find tags that are commented out, or inside script tag etc.\n\n    :param html: HTML page\n    :param tag: tag name to find\n    :return: generator with Tags"}]}, {"id": "identity_6736", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nSave a vectorized image to file."}]}, {"id": "identity_1494", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nBuild an ordered list of Distribution instances for component models.\n\n    Args:\n      num_timesteps: Python `int` number of timesteps to model.\n      param_vals: a list of `Tensor` parameter values in order corresponding to\n        `self.parameters`, or a dict mapping from parameter names to values.\n      initial_step: optional `int` specifying the initial timestep to model.\n        This is relevant when the model contains time-varying components,\n        e.g., holidays or seasonality.\n\n    Returns:\n      component_ssms: a Python list of `LinearGaussianStateSpaceModel`\n        Distribution objects, in order corresponding to `self.components`."}]}, {"id": "identity_164", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturns whether or not this dependency is met for a given task instance. A\n        dependency is considered met if all of the dependency statuses it reports are\n        passing.\n\n        :param ti: the task instance to see if this dependency is met for\n        :type ti: airflow.models.TaskInstance\n        :param session: database session\n        :type session: sqlalchemy.orm.session.Session\n        :param dep_context: The context this dependency is being checked under that stores\n            state that can be used by this dependency.\n        :type dep_context: BaseDepContext"}]}, {"id": "identity_1086", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nIf given an ordered list of parameter values, build a name:value map.\n\n    This is a utility method that allows parameter values to be specified as\n    either lists or dicts, by transforming lists to a canonical dict\n    representation.\n\n    Args:\n      param_vals: Python list (or other `iterable`) of `Tensor` values\n        corresponding to the parameters listed in `self.parameters`,\n        OR a map (Python `dict`) of parameter names to values.\n\n    Returns:\n      param_map: Python `dict` mapping from the names given in `self.parameters`\n        to the specified parameter values."}]}, {"id": "identity_1967", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturn function's declared arguments as a string.\n\n    For example for this function it returns \"func, highlight=None\"; for the ``_wrap`` function it returns\n    \"text, wrap_at=120, indent=4\". This should usually coincide with the function's declaration (the part\n    which is inside the parentheses)."}]}, {"id": "identity_2589", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReplicate a VM image to multiple target locations. This operation\n        is only for publishers. You have to be registered as image publisher\n        with Microsoft Azure to be able to call this.\n\n        vm_image_name:\n            Specifies the name of the VM Image that is to be used for\n            replication\n        regions:\n            Specified a list of regions to replicate the image to\n            Note: The regions in the request body are not additive. If a VM\n            Image has already been replicated to Regions A, B, and C, and\n            a request is made to replicate to Regions A and D, the VM\n            Image will remain in Region A, will be replicated in Region D,\n            and will be unreplicated from Regions B and C\n        offer:\n            Specifies the publisher defined name of the offer. The allowed\n            characters are uppercase or lowercase letters, digit,\n            hypen(-), period (.).The maximum allowed length is 64 characters.\n        sku:\n            Specifies the publisher defined name of the Sku. The allowed\n            characters are uppercase or lowercase letters, digit,\n            hypen(-), period (.). The maximum allowed length is 64 characters.\n        version:\n            Specifies the publisher defined version of the image.\n            The allowed characters are digit and period.\n            Format: <MajorVersion>.<MinorVersion>.<Patch>\n            Example: '1.0.0' or '1.1.0' The 3 version number to\n            follow standard of most of the RPs. See http://semver.org"}]}, {"id": "identity_1754", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nComputes attention vector for each item in inputs:\n       attention vector is a weighted sum of memory items.\n       Dot product between input and memory vector is used as similarity measure.\n\n       Gate mechanism is applied to attention vectors to produce output.\n\n    Args:\n        inputs: Tensor [batch_size x input_len x feature_size]\n        memory: Tensor [batch_size x memory_len x feature_size]\n        mask: inputs mask\n        att_size: hidden size of attention\n        keep_prob: dropout keep_prob\n        scope:\n\n    Returns:\n        attention vectors [batch_size x input_len x (feature_size + feature_size)]"}]}, {"id": "identity_1860", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nPopulates generated response with additional data conforming Alexa response specification.\n\n        Args:\n            response: Raw user input extracted from Alexa request.\n            request: Alexa request.\n        Returns:\n            response: Response conforming Alexa response specification."}]}, {"id": "identity_1983", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nClear the output directory."}]}, {"id": "identity_5698", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\ncheck if the getattr is an access to a class member\n        if so, register it. Also check for access to protected\n        class member from outside its class (but ignore __special__\n        methods)"}]}, {"id": "identity_1223", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nThe binomial cumulative distribution function.\n\n  Args:\n    k: floating point `Tensor`.\n    n: floating point `Tensor`.\n    p: floating point `Tensor`.\n\n  Returns:\n    `sum_{j=0}^k p^j (1 - p)^(n - j)`."}]}, {"id": "identity_8301", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nSend off parsed telegram to handling callback."}]}, {"id": "identity_4166", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nRemove all of the descendant operation nodes of node."}]}, {"id": "identity_6325", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nDeform a mesh along a parametric curve function\n\n    Provide a parametric curve function with z as the parameter. This will\n    deform the xy cross section of the mesh along the curve as z increases.\n\n    Source: http://blackpawn.com/texts/pqtorus/\n\n    Methodology:\n    T  = P' - P\n    N1 = P' + P\n    B  = T x N1\n    N  = B x T\n\n    newPoint = point.x*N + point.y*B"}]}, {"id": "identity_1264", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReplaces an element at supplied index."}]}, {"id": "identity_1585", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nThe inverse LU decomposition, `X == lu_reconstruct(*tf.linalg.lu(X))`.\n\n  Args:\n    lower_upper: `lu` as returned by `tf.linalg.lu`, i.e., if\n      `matmul(P, matmul(L, U)) = X` then `lower_upper = L + U - eye`.\n    perm: `p` as returned by `tf.linag.lu`, i.e., if\n      `matmul(P, matmul(L, U)) = X` then `perm = argmax(P)`.\n    validate_args: Python `bool` indicating whether arguments should be checked\n      for correctness.\n      Default value: `False` (i.e., don't validate arguments).\n    name: Python `str` name given to ops managed by this object.\n      Default value: `None` (i.e., \"lu_reconstruct\").\n\n  Returns:\n    x: The original input to `tf.linalg.lu`, i.e., `x` as in,\n      `lu_reconstruct(*tf.linalg.lu(x))`.\n\n  #### Examples\n\n  ```python\n  import numpy as np\n  import tensorflow as tf\n  import tensorflow_probability as tfp\n\n  x = [[[3., 4], [1, 2]],\n       [[7., 8], [3, 4]]]\n  x_reconstructed = tfp.math.lu_reconstruct(*tf.linalg.lu(x))\n  tf.assert_near(x, x_reconstructed)\n  # ==> True\n  ```"}]}, {"id": "identity_9394", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nSerializes into a bytestring.\n\n        :returns: An object of type Bytes."}]}, {"id": "identity_1564", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGets a Tensor of type `dtype`, 0 if `tol` is None, validation optional."}]}, {"id": "identity_4359", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturn the composition channel."}]}, {"id": "identity_6709", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nAdd new features to FeatureTable.\n        Args:\n            features (str, DataFrame): A filename to load data from, or a\n                pandas DataFrame. In either case, studies are in rows and\n                features are in columns. Values in cells reflect the weight of\n                the intersecting feature for the intersecting study. Feature\n                names and study IDs should be included as the first column\n                and first row, respectively.\n            merge (str): The merge strategy to use when merging new features\n                with old. This is passed to pandas.merge, so can be 'left',\n                'right', 'outer', or 'inner'. Defaults to outer (i.e., all data\n                in both new and old will be kept, and missing values will be\n                assigned zeros.)\n            duplicates (str): string indicating how to handle features whose\n                name matches an existing feature. Valid options:\n                    'ignore' (default): ignores the new feature, keeps old data\n                    'replace': replace the old feature's data with the new data\n                    'merge': keeps both features, renaming them so they're\n                        different\n            min_studies (int): minimum number of studies that pass threshold in\n                order to add feature.\n            threshold (float): minimum frequency threshold each study must\n                exceed in order to count towards min_studies."}]}, {"id": "identity_3938", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nSubscribes to an event, so when it's emitted all the callbacks subscribed,\n        will be executed. We are not allowing double registration.\n\n        Args\n            event (string): The event to subscribed in the form of:\n                            \"terra.<component>.<method>.<action>\"\n            callback (callable): The callback that will be executed when an event is\n                                  emitted."}]}, {"id": "identity_4452", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\npublish value to status"}]}, {"id": "identity_6317", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGeometric function using muparser lib to generate new Coordinates\n\n    You can change x, y, z for every vertex according to the function specified.\n\n    See help(mlx.muparser_ref) for muparser reference documentation.\n    It's possible to use the following per-vertex variables in the expression:\n\n    Variables (per vertex):\n        x, y, z (coordinates)\n        nx, ny, nz (normal)\n        r, g, b, a (color)\n        q (quality)\n        rad (radius)\n        vi (vertex index)\n        vtu, vtv (texture coordinates)\n        ti (texture index)\n        vsel (is the vertex selected? 1 yes, 0 no)\n        and all custom vertex attributes already defined by user.\n\n    Args:\n        x_func (str): function to generate new coordinates for x\n        y_func (str): function to generate new coordinates for y\n        z_func (str): function to generate new coordinates for z\n\n    Layer stack:\n        No impacts\n\n    MeshLab versions:\n        1.3.4BETA"}]}, {"id": "identity_7378", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nConverts py_zipkin's Kind to Protobuf's Kind.\n\n    :param kind: py_zipkin's Kind.\n    :type kind: py_zipkin.Kind\n    :return: correcponding protobuf's kind value.\n    :rtype: zipkin_pb2.Span.Kind"}]}, {"id": "identity_1195", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nHelper utility to make a field of images."}]}, {"id": "identity_4918", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nExtracts the identifier from a Slack item.\n\n        This identifier will be the mix of two fields because Slack\n        messages does not have any unique identifier. In this case,\n        'ts' and 'user' values (or 'bot_id' when the message is sent by a bot)\n        are combined because there have been cases where two messages were sent\n        by different users at the same time."}]}, {"id": "identity_7387", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nTakes a bunch of span attributes and returns a thriftpy2 representation\n    of the span. Timestamps passed in are in seconds, they're converted to\n    microseconds before thrift encoding."}]}, {"id": "identity_8138", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReceive OAuth callback request from Facebook."}]}, {"id": "identity_2087", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nMerge two datasets based on common column names.  We do not support all_x=True and all_y=True.\n        Only one can be True or none is True.  The default merge method is auto and it will default to the\n        radix method.  The radix method will return the correct merge result regardless of duplicated rows\n         in the right frame.  In addition, the radix method can perform merge even if you have string columns\n         in your frames.  If there are duplicated rows in your rite frame, they will not be included if you use\n        the hash method.  The hash method cannot perform merge if you have string columns in your left frame.\n        Hence, we consider the radix method superior to the hash method and is the default method to use.\n\n        :param H2OFrame other: The frame to merge to the current one. By default, must have at least one column in common with\n            this frame, and all columns in common are used as the merge key.  If you want to use only a subset of the\n            columns in common, rename the other columns so the columns are unique in the merged result.\n        :param bool all_x: If True, include all rows from the left/self frame\n        :param bool all_y: If True, include all rows from the right/other frame\n        :param by_x: list of columns in the current frame to use as a merge key.\n        :param by_y: list of columns in the ``other`` frame to use as a merge key. Should have the same number of\n            columns as in the ``by_x`` list.\n        :param method: string representing the merge method, one of auto(default), radix or hash.\n\n        :returns: New H2OFrame with the result of merging the current frame with the ``other`` frame."}]}, {"id": "identity_8468", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nRemoves a logical interface from a device type.\n        Parameters:\n            - typeId (string) - the device type\n            - logicalInterfaceId (string) - the id returned by the platform on creation of the logical interface\n        Throws APIException on failure."}]}, {"id": "identity_3235", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nExports the DataFrame to a file written with arrow\n\n        :param DataFrameLocal df: DataFrame to export\n        :param str path: path for file\n        :param lis[str] column_names: list of column names to export or None for all columns\n        :param str byteorder: = for native, < for little endian and > for big endian\n        :param bool shuffle: export rows in random order\n        :param bool selection: export selection or not\n        :param progress: progress callback that gets a progress fraction as argument and should return True to continue,\n                or a default progress bar when progress=True\n        :param: bool virtual: When True, export virtual columns\n        :param str sort: expression used for sorting the output\n        :param bool ascending: sort ascending (True) or descending\n        :return:"}]}, {"id": "identity_5919", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nUses cached client or create new one with specific token."}]}, {"id": "identity_5978", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nRecursively converts dictionary keys to strings."}]}, {"id": "identity_3200", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturn a sorted DataFrame, sorted by the expression 'by'\n\n        {note_copy}\n\n        {note_filter}\n\n        Example:\n\n        >>> import vaex, numpy as np\n        >>> df = vaex.from_arrays(s=np.array(['a', 'b', 'c', 'd']), x=np.arange(1,5))\n        >>> df['y'] = (df.x-1.8)**2\n        >>> df\n          #  s      x     y\n          0  a      1  0.64\n          1  b      2  0.04\n          2  c      3  1.44\n          3  d      4  4.84\n        >>> df.sort('y', ascending=False)  # Note: passing '(x-1.8)**2' gives the same result\n          #  s      x     y\n          0  d      4  4.84\n          1  c      3  1.44\n          2  a      1  0.64\n          3  b      2  0.04\n\n        :param str or expression by: expression to sort by\n        :param bool ascending: ascending (default, True) or descending (False)\n        :param str kind: kind of algorithm to use (passed to numpy.argsort)"}]}, {"id": "identity_6734", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nTake a set of discrete foci (i.e., 2-D array of xyz coordinates)\n    and generate a corresponding image, convolving each focus with a\n    hard sphere of radius r."}]}, {"id": "identity_8839", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nInitialization done before entering the debugger-command\n        loop. In particular we set up the call stack used for local\n        variable lookup and frame/up/down commands.\n\n        We return True if we should NOT enter the debugger-command\n        loop."}]}, {"id": "identity_8036", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nDelete object corresponding to path."}]}, {"id": "identity_3842", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\naxes labels"}]}, {"id": "identity_8229", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nUpdate a team membership, by ID.\n\n        Args:\n            membershipId(basestring): The team membership ID.\n            isModerator(bool): Set to True to make the person a team moderator.\n            **request_parameters: Additional request parameters (provides\n                support for parameters that may be added in the future).\n\n        Returns:\n            TeamMembership: A TeamMembership object with the updated Webex\n            Teams team-membership details.\n\n        Raises:\n            TypeError: If the parameter types are incorrect.\n            ApiError: If the Webex Teams cloud returns an error."}]}, {"id": "identity_7417", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nJoin strings together and strip whitespace in between if needed"}]}, {"id": "identity_2133", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nMove the token by `drow` rows and `dcol` columns."}]}, {"id": "identity_4219", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturn the primary acquire channel of this qubit."}]}, {"id": "identity_7966", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturns the list of vlrs of the requested type\n        Always returns a list even if there is only one VLR of type vlr_type.\n\n        >>> import pylas\n        >>> las = pylas.read(\"pylastests/extrabytes.las\")\n        >>> las.vlrs\n        [<ExtraBytesVlr(extra bytes structs: 5)>]\n        >>> las.vlrs.get(\"WktCoordinateSystemVlr\")\n        []\n        >>> las.vlrs.get(\"WktCoordinateSystemVlr\")[0]\n        Traceback (most recent call last):\n        IndexError: list index out of range\n        >>> las.vlrs.get('ExtraBytesVlr')\n        [<ExtraBytesVlr(extra bytes structs: 5)>]\n        >>> las.vlrs.get('ExtraBytesVlr')[0]\n        <ExtraBytesVlr(extra bytes structs: 5)>\n\n\n        Parameters\n        ----------\n        vlr_type: str\n                  the class name of the vlr\n\n        Returns\n        -------\n        :py:class:`list`\n            a List of vlrs matching the user_id and records_ids"}]}, {"id": "identity_7961", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nBuilds the dict mapping point format id to numpy.dtype\n    In the dtypes, bit fields are unpacked and can be accessed directly"}]}, {"id": "identity_8273", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCreate a new user account for a given organization\n\n        Only an admin can create a new user account.\n\n        Args:\n            emails(`list`): Email address(es) of the person (list of strings).\n            displayName(basestring): Full name of the person.\n            firstName(basestring): First name of the person.\n            lastName(basestring): Last name of the person.\n            avatar(basestring): URL to the person's avatar in PNG format.\n            orgId(basestring): ID of the organization to which this\n                person belongs.\n            roles(`list`): Roles of the person (list of strings containing\n                the role IDs to be assigned to the person).\n            licenses(`list`): Licenses allocated to the person (list of\n                strings - containing the license IDs to be allocated to the\n                person).\n            **request_parameters: Additional request parameters (provides\n                support for parameters that may be added in the future).\n\n        Returns:\n            Person: A Person object with the details of the created person.\n\n        Raises:\n            TypeError: If the parameter types are incorrect.\n            ApiError: If the Webex Teams cloud returns an error."}]}, {"id": "identity_5808", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nLook for removed attributes"}]}, {"id": "identity_4556", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nEnsures argument obj is a dictionary, and enforces that the keys/values conform to the types\n    specified by key_type, value_type."}]}, {"id": "identity_1369", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nBuild a callable that performs one step of Kalman mean recursion.\n\n  Args:\n    get_transition_matrix_for_timestep: callable taking a timestep\n      as an integer `Tensor` argument, and returning a `LinearOperator`\n      of shape `[latent_size, latent_size]`.\n    get_transition_noise_for_timestep: callable taking a timestep as\n      an integer `Tensor` argument, and returning a\n      `MultivariateNormalLinearOperator` of event shape\n      `[latent_size]`.\n    get_observation_matrix_for_timestep: callable taking a timestep\n      as an integer `Tensor` argument, and returning a `LinearOperator`\n      of shape `[observation_size, observation_size]`.\n    get_observation_noise_for_timestep: callable taking a timestep as\n      an integer `Tensor` argument, and returning a\n      `MultivariateNormalLinearOperator` of event shape\n      `[observation_size]`.\n\n  Returns:\n    kalman_mean_step: a callable that computes latent state and\n      observation means at time `t`, given latent mean at time `t-1`."}]}, {"id": "identity_8373", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nChecks if a Pong message was received.\n\n        :return:"}]}, {"id": "identity_7752", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nInvoke a dry-run of the scheduler for the job.\n\n           https://www.nomadproject.io/docs/http/job.html\n\n            arguments:\n              - id\n              - job, dict\n              - diff, boolean\n              - policy_override, boolean\n            returns: dict\n            raises:\n              - nomad.api.exceptions.BaseNomadException\n              - nomad.api.exceptions.URLNotFoundNomadException"}]}, {"id": "identity_3102", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nDecorator to transparantly accept delayed computation.\n\n    Example:\n\n    >>> delayed_sum = ds.sum(ds.E, binby=ds.x, limits=limits,\n    >>>                   shape=4, delay=True)\n    >>> @vaex.delayed\n    >>> def total_sum(sums):\n    >>>     return sums.sum()\n    >>> sum_of_sums = total_sum(delayed_sum)\n    >>> ds.execute()\n    >>> sum_of_sums.get()\n    See the tutorial for a more complete example https://docs.vaex.io/en/latest/tutorial.html#Parallel-computations"}]}, {"id": "identity_277", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGets a Model. Blocks until finished."}]}, {"id": "identity_5995", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCall the method repeatedly such that it will return a PKey object."}]}, {"id": "identity_6540", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturn \"data\" value on self.data\n\n        :return: data to send\n        :rtype: str"}]}, {"id": "identity_8244", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nstrptime with the Webex Teams DateTime format as the default."}]}, {"id": "identity_5161", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCreate a http session and initialize the retry object."}]}, {"id": "identity_3951", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturns a copy of a Layout instance."}]}, {"id": "identity_1407", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReplaces the rightmost dims in a `Tensor` representing a shape.\n\n  Args:\n    input_shape: a rank-1 `Tensor` of integers\n    event_shape_in: the event shape expected to be present in rightmost dims\n      of `shape_in`.\n    event_shape_out: the event shape with which to replace `event_shape_in` in\n      the rightmost dims of `input_shape`.\n    validate_args: Python `bool` indicating whether arguments should\n      be checked for correctness.\n\n  Returns:\n    output_shape: A rank-1 integer `Tensor` with the same contents as\n      `input_shape` except for the event dims, which are replaced with\n      `event_shape_out`."}]}, {"id": "identity_567", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nFor the documentation see:\n        :py:class:`~airflow.contrib.operators.gcp_vision_operator.CloudVisionReferenceImageCreateOperator`"}]}, {"id": "identity_1906", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCalculates F-1 score between y_true and y_predicted\n        F-1 score uses the best matching y_true answer\n\n    The same as in SQuAD-v2.0\n\n    Args:\n        y_true: list of correct answers (correct answers are represented by list of strings)\n        y_predicted: list of predicted answers\n\n    Returns:\n        F-1 score : float"}]}, {"id": "identity_7188", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nQuery the configured SLUGS service with the provided credentials.\n\n        Args:\n            connection_certificate (cryptography.x509.Certificate): An X.509\n                certificate object obtained from the connection being\n                authenticated. Required for SLUGS authentication.\n            connection_info (tuple): A tuple of information pertaining to the\n                connection being authenticated, including the source IP address\n                and a timestamp (e.g., ('127.0.0.1', 1519759267.467451)).\n                Optional, defaults to None. Ignored for SLUGS authentication.\n            request_credentials (list): A list of KMIP Credential structures\n                containing credential information to use for authentication.\n                Optional, defaults to None. Ignored for SLUGS authentication."}]}, {"id": "identity_6524", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturns the shape of the data."}]}, {"id": "identity_9466", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nAppend a child node with a given name, which has a (nameless) \n        plain-text child with the given text value."}]}, {"id": "identity_5506", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCheck if the given owner should be ignored\n\n    This will verify if the owner's module is in *ignored_modules*\n    or the owner's module fully qualified name is in *ignored_modules*\n    or if the *ignored_modules* contains a pattern which catches\n    the fully qualified name of the module.\n\n    Also, similar checks are done for the owner itself, if its name\n    matches any name from the *ignored_classes* or if its qualified\n    name can be found in *ignored_classes*."}]}, {"id": "identity_3466", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nUses a flexible heuristic to pick peaks in a signal.\n\n    A sample n is selected as an peak if the corresponding x[n]\n    fulfills the following three conditions:\n\n    1. `x[n] == max(x[n - pre_max:n + post_max])`\n    2. `x[n] >= mean(x[n - pre_avg:n + post_avg]) + delta`\n    3. `n - previous_n > wait`\n\n    where `previous_n` is the last sample picked as a peak (greedily).\n\n    This implementation is based on [1]_ and [2]_.\n\n    .. [1] Boeck, Sebastian, Florian Krebs, and Markus Schedl.\n        \"Evaluating the Online Capabilities of Onset Detection Methods.\" ISMIR.\n        2012.\n\n    .. [2] https://github.com/CPJKU/onset_detection/blob/master/onset_program.py\n\n\n    Parameters\n    ----------\n    x         : np.ndarray [shape=(n,)]\n        input signal to peak picks from\n\n    pre_max   : int >= 0 [scalar]\n        number of samples before `n` over which max is computed\n\n    post_max  : int >= 1 [scalar]\n        number of samples after `n` over which max is computed\n\n    pre_avg   : int >= 0 [scalar]\n        number of samples before `n` over which mean is computed\n\n    post_avg  : int >= 1 [scalar]\n        number of samples after `n` over which mean is computed\n\n    delta     : float >= 0 [scalar]\n        threshold offset for mean\n\n    wait      : int >= 0 [scalar]\n        number of samples to wait after picking a peak\n\n    Returns\n    -------\n    peaks     : np.ndarray [shape=(n_peaks,), dtype=int]\n        indices of peaks in `x`\n\n    Raises\n    ------\n    ParameterError\n        If any input lies outside its defined range\n\n    Examples\n    --------\n    >>> y, sr = librosa.load(librosa.util.example_audio_file(), duration=15)\n    >>> onset_env = librosa.onset.onset_strength(y=y, sr=sr,\n    ...                                          hop_length=512,\n    ...                                          aggregate=np.median)\n    >>> peaks = librosa.util.peak_pick(onset_env, 3, 3, 3, 5, 0.5, 10)\n    >>> peaks\n    array([  4,  23,  73, 102, 142, 162, 182, 211, 261, 301, 320,\n           331, 348, 368, 382, 396, 411, 431, 446, 461, 476, 491,\n           510, 525, 536, 555, 570, 590, 609, 625, 639])\n\n    >>> import matplotlib.pyplot as plt\n    >>> times = librosa.frames_to_time(np.arange(len(onset_env)),\n    ...                                sr=sr, hop_length=512)\n    >>> plt.figure()\n    >>> ax = plt.subplot(2, 1, 2)\n    >>> D = librosa.stft(y)\n    >>> librosa.display.specshow(librosa.amplitude_to_db(D, ref=np.max),\n    ...                          y_axis='log', x_axis='time')\n    >>> plt.subplot(2, 1, 1, sharex=ax)\n    >>> plt.plot(times, onset_env, alpha=0.8, label='Onset strength')\n    >>> plt.vlines(times[peaks], 0,\n    ...            onset_env.max(), color='r', alpha=0.8,\n    ...            label='Selected peaks')\n    >>> plt.legend(frameon=True, framealpha=0.8)\n    >>> plt.axis('tight')\n    >>> plt.tight_layout()"}]}, {"id": "identity_8940", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCheck to see if any of the signal handlers we are interested in have\n        changed or is not initially set. Change any that are not right."}]}, {"id": "identity_5180", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nParse a Phabricator tasks JSON stream.\n\n        The method parses a JSON stream and returns a list iterator.\n        Each item is a dictionary that contains the task parsed data.\n\n        :param raw_json: JSON string to parse\n\n        :returns: a generator of parsed tasks"}]}, {"id": "identity_7350", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nDynamically creates and returns a sitetree item object.\n\n    :param str|unicode title:\n\n    :param str|unicode url:\n\n    :param list, set children: a list of children for tree item. Children should also be created by `item` function.\n\n    :param bool url_as_pattern: consider URL as a name of a named URL\n\n    :param str|unicode hint: hints are usually shown to users\n\n    :param str|unicode alias: item name to address it from templates\n\n    :param str|unicode description: additional information on item (usually is not shown to users)\n\n    :param bool in_menu: show this item in menus\n\n    :param bool in_breadcrumbs: show this item in breadcrumbs\n\n    :param bool in_sitetree: show this item in sitetrees\n\n    :param bool access_loggedin: show item to logged in users only\n\n    :param bool access_guest: show item to guest users only\n\n    :param list|str||unicode|int, Permission access_by_perms: restrict access to users with these permissions.\n\n        This can be set to one or a list of permission names, IDs or Permission instances.\n\n        Permission names are more portable and should be in a form `<app_label>.<perm_codename>`, e.g.:\n            my_app.allow_save\n\n\n    :param bool perms_mode_all: permissions set interpretation rule:\n                True - user should have all the permissions;\n                False - user should have any of chosen permissions.\n\n    :rtype: TreeItemBase"}]}, {"id": "identity_5342", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nSync directory to directory."}]}, {"id": "identity_5748", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\n`not len(S)` must become `not S` regardless if the parent block\n        is a test condition or something else (boolean expression)\n        e.g. `if not len(S):`"}]}, {"id": "identity_8081", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nResolve a path based on a dictionary of manager prefixes.\n\n    Returns a triple of (prefix, manager, manager_relative_path)."}]}, {"id": "identity_6233", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nAdd function 'enrichr' argument parsers."}]}, {"id": "identity_923", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturns `max` or `mask` if `max` is not finite."}]}, {"id": "identity_5281", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nParses a stream of tokens and splits it into sentences (using C{soft_delimiter} tokens) \n    and blocks (using C{hard_delimiter} tokens) for use with the L{align_texts} function."}]}, {"id": "identity_3772", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCompute the mutual information of a bipartite state.\n\n    Args:\n        state (array_like): a bipartite state-vector or density-matrix.\n        d0 (int): dimension of the first subsystem.\n        d1 (int or None): dimension of the second subsystem.\n\n    Returns:\n        float: The mutual information S(rho_A) + S(rho_B) - S(rho_AB)."}]}, {"id": "identity_2866", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCompletes the restore operation on a managed database.\n\n        :param location_name: The name of the region where the resource is\n         located.\n        :type location_name: str\n        :param operation_id: Management operation id that this request tries\n         to complete.\n        :type operation_id: str\n        :param last_backup_name: The last backup name to apply\n        :type last_backup_name: str\n        :param dict custom_headers: headers that will be added to the request\n        :param bool raw: The poller return type is ClientRawResponse, the\n         direct response alongside the deserialized response\n        :param polling: True for ARMPolling, False for no polling, or a\n         polling object for personal polling strategy\n        :return: An instance of LROPoller that returns None or\n         ClientRawResponse<None> if raw==True\n        :rtype: ~msrestazure.azure_operation.AzureOperationPoller[None] or\n         ~msrestazure.azure_operation.AzureOperationPoller[~msrest.pipeline.ClientRawResponse[None]]\n        :raises: :class:`CloudError<msrestazure.azure_exceptions.CloudError>`"}]}, {"id": "identity_8652", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nMove an existing key to the beginning or end of this ordered bidict.\n\n        The item is moved to the end if *last* is True, else to the beginning.\n\n        :raises KeyError: if the key does not exist"}]}, {"id": "identity_5691", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\ninit visit variable _accessed"}]}, {"id": "identity_880", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\n1x1 convolution"}]}, {"id": "identity_8364", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nStart a step."}]}, {"id": "identity_1002", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturns sorted array of primes such that `2 <= prime < n`."}]}, {"id": "identity_2032", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nSave the current model progress into ``self._progress_data``, and update ``self._next_poll_time``.\n\n        :param res: tuple (progress level, poll delay).\n        :param now: current timestamp."}]}, {"id": "identity_6815", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nPause playback on the user\u2019s account.\n\n        Parameters\n        ----------\n        device : Optional[:obj:`SomeDevice`]\n            The Device object or id of the device this command is targeting.\n            If not supplied, the user\u2019s currently active device is the target."}]}, {"id": "identity_9951", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturn the time of secondary eclipse center (calculated using `params.t0`)."}]}, {"id": "identity_7432", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nThis function is a coroutine.\n\n        Closes all connections."}]}, {"id": "identity_2874", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nSend a message and blocks until acknowledgement is received or the operation fails.\n\n        If neither the Sender nor the message has a session ID, a `ValueError` will be raised.\n\n        :param message: The message to be sent.\n        :type message: ~azure.servicebus.aio.async_message.Message\n        :raises: ~azure.servicebus.common.errors.MessageSendFailed if the message fails to\n         send.\n\n        Example:\n            .. literalinclude:: ../examples/async_examples/test_examples_async.py\n                :start-after: [START open_close_session_sender_context]\n                :end-before: [END open_close_session_sender_context]\n                :language: python\n                :dedent: 4\n                :caption: Open a sessionful Sender and send messages."}]}, {"id": "identity_3734", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nApply barrier to circuit.\n    If qargs is None, applies to all the qbits.\n    Args is a list of QuantumRegister or single qubits.\n    For QuantumRegister, applies barrier to all the qubits in that register."}]}, {"id": "identity_1596", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGenerate the slices for building an autoregressive mask."}]}, {"id": "identity_6111", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGet the public key of the certificate signing request.\n\n        :return: The public key.\n        :rtype: :py:class:`PKey`"}]}, {"id": "identity_7588", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nScans the Tangle for used addresses.\n\n    This is basically the opposite of invoking ``getNewAddresses`` with\n    ``stop=None``."}]}, {"id": "identity_8938", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nA replacement for signal.signal which chains the signal behind\n        the debugger's handler"}]}, {"id": "identity_6068", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nHelper to implement :meth:`get_finished` and\n        :meth:`get_peer_finished`.\n\n        :param function: Either :data:`SSL_get_finished`: or\n            :data:`SSL_get_peer_finished`.\n\n        :return: :data:`None` if the desired message has not yet been\n            received, otherwise the contents of the message.\n        :rtype: :class:`bytes` or :class:`NoneType`"}]}, {"id": "identity_8716", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nFind all vcard files inside this address book.\n\n        If a search string is given only files which contents match that will\n        be returned.\n\n        :param search: a regular expression to limit the results\n        :type search: str\n        :param search_in_source_files: apply search regexp directly on the .vcf files to speed up parsing (less accurate)\n        :type search_in_source_files: bool\n        :returns: the paths of the vcard files\n        :rtype: generator"}]}, {"id": "identity_4755", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nNotify observers of a new value.\n\n        value -- new value"}]}, {"id": "identity_7335", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nRender helper is used by template node functions\n    to render given template with given tree items in context."}]}, {"id": "identity_3289", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nWrite a single property to the file in Java properties format.\n\n    :param fh: a writable file-like object\n    :param key: the key to write\n    :param value: the value to write"}]}, {"id": "identity_9010", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nextract_concepts takes a list of sentences and ids(optional)\n            then returns a list of Concept objects extracted via\n            MetaMap.\n\n            Supported Options:\n                Composite Phrase -Q\n                Word Sense Disambiguation -y\n                use strict model -A\n                use relaxed model -C\n                allow large N -l\n                allow overmatches -o\n                allow concept gaps -g\n                term processing -z\n                No Derivational Variants -d\n                All Derivational Variants -D\n                Ignore Word Order -i\n                Allow Acronym Variants -a\n                Unique Acronym Variants -u\n                Prefer Multiple Concepts -Y\n                Ignore Stop Phrases -K\n                Compute All Mappings -b\n                MM Data Version -V\n                Exclude Sources -e\n                Restrict to Sources -R\n                Restrict to Semantic Types -J\n                Exclude Semantic Types -k\n                \n\n            For information about the available options visit\n            http://metamap.nlm.nih.gov/.\n\n            Note: If an error is encountered the process will be closed\n                  and whatever was processed, if anything, will be\n                  returned along with the error found."}]}, {"id": "identity_5343", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nSync files to S3. Does implement deletions if syncing TO s3.\n       Currently identical to get/put -r -f --sync-check with exception of deletions."}]}, {"id": "identity_638", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nreturns a json response from a json serializable python object"}]}, {"id": "identity_240", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nFinds named entities in the text along with entity types,\n        salience, mentions for each entity, and other properties.\n\n        :param document: Input document.\n            If a dict is provided, it must be of the same form as the protobuf message Document\n        :type document: dict or class google.cloud.language_v1.types.Document\n        :param encoding_type: The encoding type used by the API to calculate offsets.\n        :type encoding_type: google.cloud.language_v1.types.EncodingType\n        :param retry: A retry object used to retry requests. If None is specified, requests will not be\n            retried.\n        :type retry: google.api_core.retry.Retry\n        :param timeout: The amount of time, in seconds, to wait for the request to complete. Note that if\n            retry is specified, the timeout applies to each individual attempt.\n        :type timeout: float\n        :param metadata: Additional metadata that is provided to the method.\n        :type metadata: sequence[tuple[str, str]]]\n        :rtype: google.cloud.language_v1.types.AnalyzeEntitiesResponse"}]}, {"id": "identity_6844", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nFormat the exctracted adblock line before passing it to the system.\n\n        :param to_format: The extracted line from the file.\n        :type to_format: str\n\n        :param result: A list of the result of this method.\n        :type result: list\n\n        :return: The list of domains or IP to test.\n        :rtype: list"}]}, {"id": "identity_1329", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nConverts logit to probabilities (or vice-versa), and returns both.\n\n  Args:\n    logits: Floating-point `Tensor` representing log-odds.\n    probs: Floating-point `Tensor` representing probabilities.\n    multidimensional: Python `bool`, default `False`. If `True`, represents\n      whether the last dimension of `logits` or `probs`, a `[N1, N2, ...  k]`\n      dimensional tensor, representing the logit or probability of `shape[-1]`\n      classes.\n    validate_args: Python `bool`, default `False`. When `True`, either assert `0\n      <= probs <= 1` (if not `multidimensional`) or that the last dimension of\n      `probs` sums to one.\n    name: A name for this operation (optional).\n    dtype: `tf.DType` to prefer when converting args to `Tensor`s.\n\n  Returns:\n    logits, probs: Tuple of `Tensor`s. If `probs` has an entry that is `0` or\n      `1`, then the corresponding entry in the returned logit will be `-Inf` and\n      `Inf` respectively.\n\n  Raises:\n    ValueError: if neither `probs` nor `logits` were passed in, or both were."}]}, {"id": "identity_6432", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturns memory stats for a package."}]}, {"id": "identity_4704", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturns the names of the supplied arguments to the given function."}]}, {"id": "identity_5985", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nDecode base64 string."}]}, {"id": "identity_7682", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nFor backwards compatibility."}]}, {"id": "identity_2349", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturns H2OPCA object which implements fit and transform method to be used in sklearn.Pipeline properly.\n        All parameters defined in self.__params, should be input parameters in H2OPCA.__init__ method.\n\n        :returns: H2OPCA object"}]}, {"id": "identity_8112", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nQueue an instance to be fetched from the database."}]}, {"id": "identity_198", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\n:return: whether all file paths have been processed max_runs times"}]}, {"id": "identity_835", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nA restful endpoint that returns external links for a given Operator\n\n        It queries the operator that sent the request for the links it wishes\n        to provide for a given external link name.\n\n        API: GET\n        Args: dag_id: The id of the dag containing the task in question\n              task_id: The id of the task in question\n              execution_date: The date of execution of the task\n              link_name: The name of the link reference to find the actual URL for\n\n        Returns:\n            200: {url: <url of link>, error: None} - returned when there was no problem\n                finding the URL\n            404: {url: None, error: <error message>} - returned when the operator does\n                not return a URL"}]}, {"id": "identity_8687", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\n:rtype: str"}]}, {"id": "identity_3908", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturns total number of gate operations in circuit.\n\n        Returns:\n            int: Total number of gate operations."}]}, {"id": "identity_3712", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturn a new circuit that has been optimized."}]}, {"id": "identity_6759", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGet an albums tracks by an ID.\n\n        Parameters\n        ----------\n        spotify_id : str\n            The spotify_id to search by.\n        limit : Optional[int]\n            The maximum number of items to return. Default: 20. Minimum: 1. Maximum: 50.\n        offset : Optiona[int]\n            The offset of which Spotify should start yielding from.\n        market : Optional[str]\n            An ISO 3166-1 alpha-2 country code."}]}, {"id": "identity_1199", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nBuilds an Iterator switching between train and heldout data."}]}, {"id": "identity_1025", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nMultiply tensor of vectors by matrices."}]}, {"id": "identity_4980", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGet the issue data by its ID"}]}, {"id": "identity_6667", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nLoad feature data from a 2D ndarray on disk."}]}, {"id": "identity_7334", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nParses sitetree_menu tag parameters.\n\n        {% sitetree_menu from \"mytree\" include \"trunk,1,level3\" %}\n        Used to render trunk, branch with id 1 and branch aliased 'level3'\n        elements from \"mytree\" site tree as a menu.\n\n        These are reserved aliases:\n            * 'trunk' - items without parents\n            * 'this-children' - items under item resolved as current for the current page\n            * 'this-siblings' - items under parent of item resolved as current for\n              the current page (current item included)\n            * 'this-ancestor-children' - items under grandparent item (closest to root)\n              for the item resolved as current for the current page\n\n        {% sitetree_menu from \"mytree\" include \"trunk,1,level3\" template \"sitetree/mymenu.html\" %}"}]}, {"id": "identity_2423", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nThe Bing Spell Check API lets you perform contextual grammar and spell\n        checking. Bing has developed a web-based spell-checker that leverages\n        machine learning and statistical machine translation to dynamically\n        train a constantly evolving and highly contextual algorithm. The\n        spell-checker is based on a massive corpus of web searches and\n        documents.\n\n        :param text: The text string to check for spelling and grammar errors.\n         The combined length of the text string, preContextText string, and\n         postContextText string may not exceed 10,000 characters. You may\n         specify this parameter in the query string of a GET request or in the\n         body of a POST request. Because of the query string length limit,\n         you'll typically use a POST request unless you're checking only short\n         strings.\n        :type text: str\n        :param accept_language: A comma-delimited list of one or more\n         languages to use for user interface strings. The list is in decreasing\n         order of preference. For additional information, including expected\n         format, see\n         [RFC2616](http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html).\n         This header and the setLang query parameter are mutually exclusive; do\n         not specify both. If you set this header, you must also specify the cc\n         query parameter. Bing will use the first supported language it finds\n         from the list, and combine that language with the cc parameter value\n         to determine the market to return results for. If the list does not\n         include a supported language, Bing will find the closest language and\n         market that supports the request, and may use an aggregated or default\n         market for the results instead of a specified one. You should use this\n         header and the cc query parameter only if you specify multiple\n         languages; otherwise, you should use the mkt and setLang query\n         parameters. A user interface string is a string that's used as a label\n         in a user interface. There are very few user interface strings in the\n         JSON response objects. Any links in the response objects to Bing.com\n         properties will apply the specified language.\n        :type accept_language: str\n        :param pragma: By default, Bing returns cached content, if available.\n         To prevent Bing from returning cached content, set the Pragma header\n         to no-cache (for example, Pragma: no-cache).\n        :type pragma: str\n        :param user_agent: The user agent originating the request. Bing uses\n         the user agent to provide mobile users with an optimized experience.\n         Although optional, you are strongly encouraged to always specify this\n         header. The user-agent should be the same string that any commonly\n         used browser would send. For information about user agents, see [RFC\n         2616](http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html).\n        :type user_agent: str\n        :param client_id: Bing uses this header to provide users with\n         consistent behavior across Bing API calls. Bing often flights new\n         features and improvements, and it uses the client ID as a key for\n         assigning traffic on different flights. If you do not use the same\n         client ID for a user across multiple requests, then Bing may assign\n         the user to multiple conflicting flights. Being assigned to multiple\n         conflicting flights can lead to an inconsistent user experience. For\n         example, if the second request has a different flight assignment than\n         the first, the experience may be unexpected. Also, Bing can use the\n         client ID to tailor web results to that client ID\u2019s search history,\n         providing a richer experience for the user. Bing also uses this header\n         to help improve result rankings by analyzing the activity generated by\n         a client ID. The relevance improvements help with better quality of\n         results delivered by Bing APIs and in turn enables higher\n         click-through rates for the API consumer. IMPORTANT: Although\n         optional, you should consider this header required. Persisting the\n         client ID across multiple requests for the same end user and device\n         combination enables 1) the API consumer to receive a consistent user\n         experience, and 2) higher click-through rates via better quality of\n         results from the Bing APIs. Each user that uses your application on\n         the device must have a unique, Bing generated client ID. If you do not\n         include this header in the request, Bing generates an ID and returns\n         it in the X-MSEdge-ClientID response header. The only time that you\n         should NOT include this header in a request is the first time the user\n         uses your app on that device. Use the client ID for each Bing API\n         request that your app makes for this user on the device. Persist the\n         client ID. To persist the ID in a browser app, use a persistent HTTP\n         cookie to ensure the ID is used across all sessions. Do not use a\n         session cookie. For other apps such as mobile apps, use the device's\n         persistent storage to persist the ID. The next time the user uses your\n         app on that device, get the client ID that you persisted. Bing\n         responses may or may not include this header. If the response includes\n         this header, capture the client ID and use it for all subsequent Bing\n         requests for the user on that device. If you include the\n         X-MSEdge-ClientID, you must not include cookies in the request.\n        :type client_id: str\n        :param client_ip: The IPv4 or IPv6 address of the client device. The\n         IP address is used to discover the user's location. Bing uses the\n         location information to determine safe search behavior. Although\n         optional, you are encouraged to always specify this header and the\n         X-Search-Location header. Do not obfuscate the address (for example,\n         by changing the last octet to 0). Obfuscating the address results in\n         the location not being anywhere near the device's actual location,\n         which may result in Bing serving erroneous results.\n        :type client_ip: str\n        :param location: A semicolon-delimited list of key/value pairs that\n         describe the client's geographical location. Bing uses the location\n         information to determine safe search behavior and to return relevant\n         local content. Specify the key/value pair as <key>:<value>. The\n         following are the keys that you use to specify the user's location.\n         lat (required): The latitude of the client's location, in degrees. The\n         latitude must be greater than or equal to -90.0 and less than or equal\n         to +90.0. Negative values indicate southern latitudes and positive\n         values indicate northern latitudes. long (required): The longitude of\n         the client's location, in degrees. The longitude must be greater than\n         or equal to -180.0 and less than or equal to +180.0. Negative values\n         indicate western longitudes and positive values indicate eastern\n         longitudes. re (required): The radius, in meters, which specifies the\n         horizontal accuracy of the coordinates. Pass the value returned by the\n         device's location service. Typical values might be 22m for GPS/Wi-Fi,\n         380m for cell tower triangulation, and 18,000m for reverse IP lookup.\n         ts (optional): The UTC UNIX timestamp of when the client was at the\n         location. (The UNIX timestamp is the number of seconds since January\n         1, 1970.) head (optional): The client's relative heading or direction\n         of travel. Specify the direction of travel as degrees from 0 through\n         360, counting clockwise relative to true north. Specify this key only\n         if the sp key is nonzero. sp (optional): The horizontal velocity\n         (speed), in meters per second, that the client device is traveling.\n         alt (optional): The altitude of the client device, in meters. are\n         (optional): The radius, in meters, that specifies the vertical\n         accuracy of the coordinates. Specify this key only if you specify the\n         alt key. Although many of the keys are optional, the more information\n         that you provide, the more accurate the location results are. Although\n         optional, you are encouraged to always specify the user's geographical\n         location. Providing the location is especially important if the\n         client's IP address does not accurately reflect the user's physical\n         location (for example, if the client uses VPN). For optimal results,\n         you should include this header and the  X-Search-ClientIP header, but\n         at a minimum, you should include this header.\n        :type location: str\n        :param action_type: A string that's used by logging to determine\n         whether the request is coming from an interactive session or a page\n         load. The following are the possible values. 1) Edit\u2014The request is\n         from an interactive session 2) Load\u2014The request is from a page load.\n         Possible values include: 'Edit', 'Load'\n        :type action_type: str or\n         ~azure.cognitiveservices.language.spellcheck.models.ActionType\n        :param app_name: The unique name of your app. The name must be known\n         by Bing. Do not include this parameter unless you have previously\n         contacted Bing to get a unique app name. To get a unique name, contact\n         your Bing Business Development manager.\n        :type app_name: str\n        :param country_code: A 2-character country code of the country where\n         the results come from. This API supports only the United States\n         market. If you specify this query parameter, it must be set to us. If\n         you set this parameter, you must also specify the Accept-Language\n         header. Bing uses the first supported language it finds from the\n         languages list, and combine that language with the country code that\n         you specify to determine the market to return results for. If the\n         languages list does not include a supported language, Bing finds the\n         closest language and market that supports the request, or it may use\n         an aggregated or default market for the results instead of a specified\n         one. You should use this query parameter and the Accept-Language query\n         parameter only if you specify multiple languages; otherwise, you\n         should use the mkt and setLang query parameters. This parameter and\n         the mkt query parameter are mutually exclusive\u2014do not specify both.\n        :type country_code: str\n        :param client_machine_name: A unique name of the device that the\n         request is being made from. Generate a unique value for each device\n         (the value is unimportant). The service uses the ID to help debug\n         issues and improve the quality of corrections.\n        :type client_machine_name: str\n        :param doc_id: A unique ID that identifies the document that the text\n         belongs to. Generate a unique value for each document (the value is\n         unimportant). The service uses the ID to help debug issues and improve\n         the quality of corrections.\n        :type doc_id: str\n        :param market: The market where the results come from. You are\n         strongly encouraged to always specify the market, if known. Specifying\n         the market helps Bing route the request and return an appropriate and\n         optimal response. This parameter and the cc query parameter are\n         mutually exclusive\u2014do not specify both.\n        :type market: str\n        :param session_id: A unique ID that identifies this user session.\n         Generate a unique value for each user session (the value is\n         unimportant). The service uses the ID to help debug issues and improve\n         the quality of corrections\n        :type session_id: str\n        :param set_lang: The language to use for user interface strings.\n         Specify the language using the ISO 639-1 2-letter language code. For\n         example, the language code for English is EN. The default is EN\n         (English). Although optional, you should always specify the language.\n         Typically, you set setLang to the same language specified by mkt\n         unless the user wants the user interface strings displayed in a\n         different language. This parameter and the Accept-Language header are\n         mutually exclusive\u2014do not specify both. A user interface string is a\n         string that's used as a label in a user interface. There are few user\n         interface strings in the JSON response objects. Also, any links to\n         Bing.com properties in the response objects apply the specified\n         language.\n        :type set_lang: str\n        :param user_id: A unique ID that identifies the user. Generate a\n         unique value for each user (the value is unimportant). The service\n         uses the ID to help debug issues and improve the quality of\n         corrections.\n        :type user_id: str\n        :param mode: The type of spelling and grammar checks to perform. The\n         following are the possible values (the values are case insensitive).\n         The default is Proof. 1) Proof\u2014Finds most spelling and grammar\n         mistakes. 2) Spell\u2014Finds most spelling mistakes but does not find some\n         of the grammar errors that Proof catches (for example, capitalization\n         and repeated words). Possible values include: 'proof', 'spell'\n        :type mode: str\n        :param pre_context_text: A string that gives context to the text\n         string. For example, the text string petal is valid. However, if you\n         set preContextText to bike, the context changes and the text string\n         becomes not valid. In this case, the API suggests that you change\n         petal to pedal (as in bike pedal). This text is not checked for\n         grammar or spelling errors. The combined length of the text string,\n         preContextText string, and postContextText string may not exceed\n         10,000 characters. You may specify this parameter in the query string\n         of a GET request or in the body of a POST request.\n        :type pre_context_text: str\n        :param post_context_text: A string that gives context to the text\n         string. For example, the text string read is valid. However, if you\n         set postContextText to carpet, the context changes and the text string\n         becomes not valid. In this case, the API suggests that you change read\n         to red (as in red carpet). This text is not checked for grammar or\n         spelling errors. The combined length of the text string,\n         preContextText string, and postContextText string may not exceed\n         10,000 characters. You may specify this parameter in the query string\n         of a GET request or in the body of a POST request.\n        :type post_context_text: str\n        :param dict custom_headers: headers that will be added to the request\n        :param bool raw: returns the direct response alongside the\n         deserialized response\n        :param operation_config: :ref:`Operation configuration\n         overrides<msrest:optionsforoperations>`.\n        :return: SpellCheck or ClientRawResponse if raw=true\n        :rtype: ~azure.cognitiveservices.language.spellcheck.models.SpellCheck\n         or ~msrest.pipeline.ClientRawResponse\n        :raises:\n         :class:`ErrorResponseException<azure.cognitiveservices.language.spellcheck.models.ErrorResponseException>`"}]}, {"id": "identity_7637", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nThe compressed point (z1, z2) has the bit order:\n    z1: (c_flag1, b_flag1, a_flag1, x1)\n    z2: (c_flag2, b_flag2, a_flag2, x2)\n    where\n    - c_flag1 is always set to 1\n    - b_flag1 indicates infinity when set to 1\n    - a_flag1 helps determine the y-coordinate when decompressing,\n    - a_flag2, b_flag2, and c_flag2 are always set to 0"}]}, {"id": "identity_3552", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nRun hook before/after spider start crawling\n        :param hook_func: aws function\n        :return:"}]}, {"id": "identity_2616", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCreate or update a VM scale set.\n\n        :param resource_group_name: The name of the resource group.\n        :type resource_group_name: str\n        :param vm_scale_set_name: The name of the VM scale set to create or\n         update.\n        :type vm_scale_set_name: str\n        :param parameters: The scale set object.\n        :type parameters:\n         ~azure.mgmt.compute.v2019_03_01.models.VirtualMachineScaleSet\n        :param dict custom_headers: headers that will be added to the request\n        :param bool raw: The poller return type is ClientRawResponse, the\n         direct response alongside the deserialized response\n        :param polling: True for ARMPolling, False for no polling, or a\n         polling object for personal polling strategy\n        :return: An instance of LROPoller that returns VirtualMachineScaleSet\n         or ClientRawResponse<VirtualMachineScaleSet> if raw==True\n        :rtype:\n         ~msrestazure.azure_operation.AzureOperationPoller[~azure.mgmt.compute.v2019_03_01.models.VirtualMachineScaleSet]\n         or\n         ~msrestazure.azure_operation.AzureOperationPoller[~msrest.pipeline.ClientRawResponse[~azure.mgmt.compute.v2019_03_01.models.VirtualMachineScaleSet]]\n        :raises: :class:`CloudError<msrestazure.azure_exceptions.CloudError>`"}]}, {"id": "identity_3764", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nConvert a Choi-matrix to a Pauli-basis superoperator.\n\n    Note that this function assumes that the Choi-matrix\n    is defined in the standard column-stacking convention\n    and is normalized to have trace 1. For a channel E this\n    is defined as: choi = (I \\\\otimes E)(bell_state).\n\n    The resulting 'rauli' R acts on input states as\n    |rho_out>_p = R.|rho_in>_p\n    where |rho> = vectorize(rho, method='pauli') for order=1\n    and |rho> = vectorize(rho, method='pauli_weights') for order=0.\n\n    Args:\n        choi (matrix): the input Choi-matrix.\n        order (int): ordering of the Pauli group vector.\n            order=1 (default) is standard lexicographic ordering.\n                Eg: [II, IX, IY, IZ, XI, XX, XY,...]\n            order=0 is ordered by weights.\n                Eg. [II, IX, IY, IZ, XI, XY, XZ, XX, XY,...]\n\n    Returns:\n        np.array: A superoperator in the Pauli basis."}]}, {"id": "identity_4954", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nRetrieve a raw HTML question and all it's information.\n\n        :param question_id: question identifier\n        :param page: page to retrieve"}]}, {"id": "identity_318", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nThis function makes an API call to Jenkins to trigger a build for 'job_name'\n        It returned a dict with 2 keys : body and headers.\n        headers contains also a dict-like object which can be queried to get\n        the location to poll in the queue.\n\n        :param jenkins_server: The jenkins server where the job should be triggered\n        :return: Dict containing the response body (key body)\n            and the headers coming along (headers)"}]}, {"id": "identity_1953", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nScore a model on the h2o cluster on the given Frame and return only the model metrics."}]}, {"id": "identity_4851", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nAdds an extra condition to this join.\n\n        Arguments:\n            field:\n                The field that the condition will apply to.\n\n            value:\n                The value to compare."}]}, {"id": "identity_3174", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nConvert cartesian to polar coordinates\n\n        :param x: expression for x\n        :param y: expression for y\n        :param radius_out: name for the virtual column for the radius\n        :param azimuth_out: name for the virtual column for the azimuth angle\n        :param propagate_uncertainties: {propagate_uncertainties}\n        :param radians: if True, azimuth is in radians, defaults to degrees\n        :return:"}]}, {"id": "identity_2262", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nLoop through all java messages that are not associated with a unit test and\n    write them into a log file.\n\n    Parameters\n    ----------\n    key :  str\n        9.general_bad_java_messages\n    val : list of list of str\n        contains the bad java messages and the message types.\n\n\n    :return: none"}]}, {"id": "identity_3438", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nArgparse function to get the program parameters"}]}, {"id": "identity_2892", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nod.clear() -> None.  Remove all items from od."}]}, {"id": "identity_6718", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nDeprecation warning decorator. Takes optional deprecation message,\n    otherwise will use a generic warning."}]}, {"id": "identity_1957", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nPretty tabulated string of all the cached data, and column names"}]}, {"id": "identity_5738", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nUpdate and check the number of nested blocks"}]}, {"id": "identity_2703", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGet the session state.\n\n        Returns None if no state has been set.\n\n        :rtype: str\n\n        Example:\n            .. literalinclude:: ../examples/async_examples/test_examples_async.py\n                :start-after: [START set_session_state]\n                :end-before: [END set_session_state]\n                :language: python\n                :dedent: 4\n                :caption: Getting and setting the state of a session."}]}, {"id": "identity_3893", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nTest if this circuit has the register r.\n\n        Args:\n            register (Register): a quantum or classical register.\n\n        Returns:\n            bool: True if the register is contained in this circuit."}]}, {"id": "identity_2365", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nMain program.  Expect script name plus 7 inputs in the following order:\n    - This script name\n    1. timestamp: time in s\n    2. jenkins_job_name (JOB_NAME)\n    3. build_id (BUILD_ID)\n    4. git hash (GIT_COMMIT)\n    5. node name (NODE_NAME)\n    6. unit test category (JUnit, PyUnit, RUnit, Hadoop)\n    7. Jenkins URL (JENKINS_URL)\n    8. Text file name where failure summaries are stored\n    9. Filename that stored all failed test info as a dictionary\n    10. duration (month) to keep data: data older tghan this input will be removed\n\n    @return: none"}]}, {"id": "identity_8445", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGet the content for a schema.  Parameters: schemaId (string), draft (boolean). Throws APIException on failure."}]}, {"id": "identity_989", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturn a list (preferred) or 1d Tensor from values, if values.ndims < 2."}]}, {"id": "identity_3147", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGives a Pandas series object containing all numpy dtypes of all columns (except hidden)."}]}, {"id": "identity_594", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGet the schema for a given datset.table.\n        see https://cloud.google.com/bigquery/docs/reference/v2/tables#resource\n\n        :param dataset_id: the dataset ID of the requested table\n        :param table_id: the table ID of the requested table\n        :return: a table schema"}]}, {"id": "identity_598", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGrant authorized view access of a dataset to a view table.\n        If this view has already been granted access to the dataset, do nothing.\n        This method is not atomic.  Running it may clobber a simultaneous update.\n\n        :param source_dataset: the source dataset\n        :type source_dataset: str\n        :param view_dataset: the dataset that the view is in\n        :type view_dataset: str\n        :param view_table: the table of the view\n        :type view_table: str\n        :param source_project: the project of the source dataset. If None,\n            self.project_id will be used.\n        :type source_project: str\n        :param view_project: the project that the view is in. If None,\n            self.project_id will be used.\n        :type view_project: str\n        :return: the datasets resource of the source dataset."}]}, {"id": "identity_7735", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nThis endpoint is used to set the health of an allocation that is in the deployment manually. In some use\n            cases, automatic detection of allocation health may not be desired. As such those task groups can be marked\n            with an upgrade policy that uses health_check = \"manual\". Those allocations must have their health marked\n            manually using this endpoint. Marking an allocation as healthy will allow the rolling upgrade to proceed.\n            Marking it as failed will cause the deployment to fail.\n\n           https://www.nomadproject.io/docs/http/deployments.html\n\n            arguments:\n              - id\n              - healthy_allocations, Specifies the set of allocation that should be marked as healthy.\n              - unhealthy_allocations,  Specifies the set of allocation that should be marked as unhealthy.\n            returns: dict\n            raises:\n              - nomad.api.exceptions.BaseNomadException\n              - nomad.api.exceptions.URLNotFoundNomadException"}]}, {"id": "identity_380", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nLists keys in a bucket under prefix and not containing delimiter\n\n        :param bucket_name: the name of the bucket\n        :type bucket_name: str\n        :param prefix: a key prefix\n        :type prefix: str\n        :param delimiter: the delimiter marks key hierarchy.\n        :type delimiter: str\n        :param page_size: pagination size\n        :type page_size: int\n        :param max_items: maximum items to return\n        :type max_items: int"}]}, {"id": "identity_1614", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nVariational loss for the VGP.\n\n    Given `observations` and `observation_index_points`, compute the\n    negative variational lower bound as specified in [Hensman, 2013][1].\n\n    Args:\n      observations: `float` `Tensor` representing collection, or batch of\n        collections, of observations corresponding to\n        `observation_index_points`. Shape has the form `[b1, ..., bB, e]`, which\n        must be brodcastable with the batch and example shapes of\n        `observation_index_points`. The batch shape `[b1, ..., bB]` must be\n        broadcastable with the shapes of all other batched parameters\n        (`kernel.batch_shape`, `observation_index_points`, etc.).\n      observation_index_points: `float` `Tensor` representing finite (batch of)\n        vector(s) of points where observations are defined. Shape has the\n        form `[b1, ..., bB, e1, f1, ..., fF]` where `F` is the number of feature\n        dimensions and must equal `kernel.feature_ndims` and `e1` is the number\n        (size) of index points in each batch (we denote it `e1` to distinguish\n        it from the numer of inducing index points, denoted `e2` below). If\n        set to `None` uses `index_points` as the origin for observations.\n        Default value: None.\n      kl_weight: Amount by which to scale the KL divergence loss between prior\n        and posterior.\n        Default value: 1.\n      name: Python `str` name prefixed to Ops created by this class.\n        Default value: \"GaussianProcess\".\n    Returns:\n      loss: Scalar tensor representing the negative variational lower bound.\n        Can be directly used in a `tf.Optimizer`.\n    Raises:\n      ValueError: if `mean_fn` is not `None` and is not callable.\n\n    #### References\n\n    [1]: Hensman, J., Lawrence, N. \"Gaussian Processes for Big Data\", 2013\n         https://arxiv.org/abs/1309.6835"}]}, {"id": "identity_1573", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nProduces a masking tensor for (in)valid production rules.\n\n    Args:\n      symbol: str, a symbol in the grammar.\n      on_value: Value to use for a valid production rule.\n      off_value: Value to use for an invalid production rule.\n\n    Returns:\n      Tensor of shape [1, num_production_rules]. An element is `on_value`\n      if its corresponding production rule has `symbol` on its left-hand-side;\n      the element is `off_value` otherwise."}]}]